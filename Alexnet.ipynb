{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225073a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Loading pre-cropped faces from folder...\n",
      "Training CNN...\n",
      "pool3 Tensor(\"pool3/MaxPool:0\", shape=(?, 19, 19, 384), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:225: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:563: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:240: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv2 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:249: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv3 = tf.layers.conv2d(conv2, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:254: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv4 = tf.layers.conv2d(conv3, filters=conv4_fmaps, kernel_size=conv4_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:259: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv5 = tf.layers.conv2d(conv4, filters=conv5_fmaps, kernel_size=conv5_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:270: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:273: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  fc2 = tf.layers.dense(fc1, n_fc2, activation=tf.nn.relu, name=\"fc2\")\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_7240/175630125.py:276: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.layers.dense(fc2, n_outputs, name=\"output\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.5764705926179886 Test accuracy: 0.5837837815284729\n",
      "1 Train accuracy: 0.6941176533699035 Test accuracy: 0.7027027010917664\n",
      "2 Train accuracy: 0.6941176533699035 Test accuracy: 0.7027027010917664\n",
      "3 Train accuracy: 0.6941176533699035 Test accuracy: 0.7027027010917664\n",
      "4 Train accuracy: 0.6941176533699035 Test accuracy: 0.7027027010917664\n",
      "5 Train accuracy: 0.729411768913269 Test accuracy: 0.737837839126587\n",
      "6 Train accuracy: 0.7823529362678527 Test accuracy: 0.7432432532310486\n",
      "7 Train accuracy: 0.8117646932601928 Test accuracy: 0.7621621608734132\n",
      "8 Train accuracy: 0.8823529481887817 Test accuracy: 0.8567567586898804\n",
      "9 Train accuracy: 0.9352941155433654 Test accuracy: 0.8837837815284729\n",
      "10 Train accuracy: 0.9117646813392639 Test accuracy: 0.8594594597816466\n",
      "11 Train accuracy: 0.8882352828979492 Test accuracy: 0.8243243217468262\n",
      "12 Train accuracy: 0.9529411554336548 Test accuracy: 0.8864864826202393\n",
      "13 Train accuracy: 0.970588219165802 Test accuracy: 0.9108107924461366\n",
      "14 Train accuracy: 0.9705882310867309 Test accuracy: 0.9270270109176636\n",
      "15 Train accuracy: 1.0 Test accuracy: 0.9378378152847291\n",
      "16 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "17 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "20 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "21 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "23 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "24 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "25 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "26 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "28 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "29 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "30 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "31 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "32 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "33 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "34 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "35 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "36 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "37 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "38 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "40 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "41 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "42 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "43 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "44 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "45 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "46 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "47 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "48 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "49 Train accuracy: 1.0 Test accuracy: 0.9459459185600281\n",
      "Saving the results...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "folder_fake = 'C:/Users/DELL/Desktop/Newfolder/fake_smiles'\n",
    "folder_real = 'C:/Users/DELL/Desktop/Newfolder/true_smiles'\n",
    "\n",
    "folder_fake_faces = 'C:/Users/DELL/Desktop/Newfolder/fake_faces'\n",
    "folder_real_faces = 'C:/Users/DELL/Desktop/Newfolder/result/true_test_fromfaces'\n",
    "\n",
    "folder_results_fake_test  = 'C:/Users/DELL/Desktop/Newfolder/result/fake_test_fromfaces'\n",
    "folder_results_real_test  = 'C:/Users/DELL/Desktop/Newfolder/result/true_test_fromfaces'\n",
    "\n",
    "detect_face = 0                                                                 # 0: using the existing cropped face images. 1: use face detectFace to crop the faces out of the original image\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    '''\n",
    "    Input:\n",
    "        folder             :The path of the image folder.\n",
    "    Output:\n",
    "        images             :A (N,) numpy array, where N is the total number of \n",
    "                            images.\n",
    "    '''\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.startswith('.') or filename == 'Thumbs.db':\n",
    "            continue\n",
    "        img = Image.open(os.path.join(folder,filename)).convert('L')            # open the image and convert to uint8 (gray scale)\n",
    "        img = np.array(img)                                                     # convert image to a numpy array\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "def resize_image(images, size):\n",
    "    '''\n",
    "    Input: \n",
    "        images             :An object of shape (N,). N is the total number of \n",
    "                            images.\n",
    "        size               :A ndarray (rows, cols) of the output image shape.\n",
    "    Output:\n",
    "        resized_images     :An (N,rows,cols) numpy array.\n",
    "    '''\n",
    "    resized_images = []\n",
    "    for i,j in enumerate(images):\n",
    "        resized_images.append(resize(images[i], ((size[0]),size[1]),            # resize the image\n",
    "                                     mode='reflect'))\n",
    "    resized_images = np.array(resized_images)                                   # convert image to a numpy array\n",
    "    return resized_images\n",
    "\n",
    "def detectFace(img):\n",
    "    '''\n",
    "    Input:\n",
    "        img                 : A gray scale image represented by numpy array.\n",
    "    Output:\n",
    "        bbox                : The four corners of bounding boxes for all \n",
    "                              detected faces in numpy arrray of shape (number \n",
    "                              of detected faces,4,2).\n",
    "                                ++++++++++++++++++\n",
    "                                +(x0,y0)  (x1,y1)+\n",
    "                                +                +\n",
    "                                +                +\n",
    "                                +      bbox      +\n",
    "                                +                +\n",
    "                                +                +\n",
    "                                +(x2,y2)  (x3,y3)+\n",
    "                                ++++++++++++++++++\n",
    "    '''\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    delta_scal = 0\n",
    "    while True:\n",
    "        faces = face_cascade.detectMultiScale(img, 3.0-delta_scal, 2)\n",
    "        if len(faces) != 0:                                                     # at least one face is detected\n",
    "            break\n",
    "        else:                                                                   # no face detected, re-detecting with new parameters...\n",
    "            if 3.0-delta_scal > 1.01:\n",
    "                delta_scal += 0.01\n",
    "            else:\n",
    "                break\n",
    "              \n",
    "    bbox = np.zeros([len(faces),4,2])\n",
    "        \n",
    "    for i, (x,y,w,h) in enumerate(faces):\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)                          # draw a red rectangle around the face  \n",
    "        bbox[i,:,:] = np.array([[y,x],[y,x+w],[y+h,x],[y+h,x+w]])\n",
    "        \n",
    "    if bbox.shape[0] != 1:\n",
    "        print(\"\\nWarning! Multiple faces detected! Image shown below...\")\n",
    "        plt.figure()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    return bbox[0,:,:].astype(int)\n",
    "\n",
    "new_size = [300,300]                                                            # the output size of all the images regardless of it's original shape\n",
    "\n",
    "if detect_face:\n",
    "    print(\"Loading original images..\")\n",
    "    images = load_images_from_folder(folder_fake)                               # load images from folder\n",
    "    X_fake = resize_image(images,new_size)                                      # resize to 300*300\n",
    "    \n",
    "    images = load_images_from_folder(folder_real)\n",
    "    X_real = resize_image(images,new_size)\n",
    "    \n",
    "    X_fake_f = np.zeros([X_fake.shape[0],new_size[0],new_size[1]])\n",
    "    X_real_f = np.zeros([X_real.shape[0],new_size[0],new_size[1]])\n",
    "    \n",
    "    toolbar_width = 1                                                           # not important, just for printing purpose...\n",
    "    sys.stdout.write(\"%s\\r\" % (\" \" * toolbar_width))                            # not important, just for printing purpose...\n",
    "    sys.stdout.flush()                                                          # not important, just for printing purpose...\n",
    "    sys.stdout.write(\"\\b\" * (toolbar_width+1))                                  # not important, just for printing purpose...\n",
    "    \n",
    "    shutil.rmtree(folder_fake_faces, ignore_errors=True)                        # remove the folder if it already exists\n",
    "    os.makedirs(folder_fake_faces)                                              # create a new folder\n",
    "    shutil.rmtree(folder_real_faces, ignore_errors=True)                        # remove the folder if it already exists\n",
    "    os.makedirs(folder_real_faces)                                              # create a new folder\n",
    "    \n",
    "    for i in range(X_fake.shape[0]):\n",
    "        bbox = detectFace((255*X_fake[i,:,:]).astype('uint8'))                  # detects the face of the original image\n",
    "        face_i = X_fake[i,bbox[0,0]:bbox[2,0],bbox[0,1]:bbox[1,1]]              # crop out the face from the original image\n",
    "        X_fake_f[i,:,:] = resize(face_i, (new_size[0],new_size[1]),\n",
    "                                 mode='reflect')                                # resize to 300*300\n",
    "        plt.imsave(folder_fake_faces+\"/fake_smile_\"+str(i)+\".jpg\",\n",
    "                   X_fake_f[i,:,:], cmap='gray')                                # save the detected face\n",
    "        \n",
    "        sys.stdout.write(\"\\rDetecting and saving fake smile faces...%.1f%%\" % \n",
    "                         (i*100/(X_fake.shape[0]-1)))                           # not important, just for printing purpose...\n",
    "        sys.stdout.flush()                                                      # not important, just for printing purpose...\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "        \n",
    "    for i in range(X_real.shape[0]):\n",
    "        bbox = detectFace((255*X_real[i,:,:]).astype('uint8'))                  # detects the face of the original image\n",
    "        face_i = X_real[i,bbox[0,0]:bbox[2,0],bbox[0,1]:bbox[1,1]]              # crop out the face from the original image\n",
    "        X_real_f[i,:,:] = resize(face_i, (new_size[0],new_size[1]), \n",
    "                                 mode='reflect')                                # resize to 300*300\n",
    "        plt.imsave(folder_real_faces+\"/real_smile\"+str(i)+\".jpg\",\n",
    "                   X_real_f[i,:,:], cmap='gray')                                # save the detected face\n",
    "        \n",
    "        sys.stdout.write(\"\\rDetecting and saving real smile faces...%.1f%%\" % \n",
    "                         (i*100/(X_real.shape[0]-1)))                           # not important, just for printing purpose...\n",
    "        sys.stdout.flush()                                                      # not important, just for printing purpose...\n",
    "    \n",
    "    sys.stdout.write(\"\\n\")                                                      # not important, just for printing purpose...\n",
    "else:\n",
    "    print(\"Loading pre-cropped faces from folder...\")\n",
    "    images = load_images_from_folder(folder_fake_faces)                         # load images from folder\n",
    "    X_fake_f = resize_image(images,new_size)                                    # resize to 300*300\n",
    "    \n",
    "    images = load_images_from_folder(folder_real_faces)                         # load images from folder\n",
    "    X_real_f = resize_image(images,new_size)                                    # resize to 300*300\n",
    "    \n",
    "y_fake = np.ones([X_fake_f.shape[0]])                                           # fake smile labels: 1\n",
    "y_real = np.zeros([X_real_f.shape[0]])                                          # real smile labels: 0\n",
    "\n",
    "print(\"Training CNN...\")\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    #tf.reset_default_graph()\n",
    "#    tf.set_random_seed(seed\n",
    "    np.random.seed(seed)                                                       \n",
    "height = new_size[0]\n",
    "width = new_size[1]\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 16\n",
    "conv1_fmaps = 48\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 50\n",
    "conv2_fmaps = 256\n",
    "conv2_ksize = 5\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "conv3_fmaps = 50\n",
    "conv3_fmaps = 384\n",
    "conv3_ksize = 3\n",
    "conv3_stride = 2\n",
    "conv3_pad = \"SAME\"\n",
    "\n",
    "conv4_fmaps = 50\n",
    "conv4_fmaps = 384\n",
    "conv4_ksize = 3\n",
    "conv4_stride = 2\n",
    "conv4_pad = \"SAME\"\n",
    "\n",
    "\n",
    "conv5_fmaps = 50\n",
    "conv5_fmaps = 256\n",
    "conv5_ksize = 3\n",
    "conv5_stride = 2\n",
    "conv5_pad = \"SAME\"\n",
    "\n",
    "pool2_fmaps = conv2_fmaps\n",
    "pool3_fmaps = conv3_fmaps\n",
    "\n",
    "n_fc1 = 64\n",
    "n_fc1 = 64\n",
    "n_fc2 = 64\n",
    "n_fc2 = n_fc1\n",
    "n_outputs = 2\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, \n",
    "                         kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "#conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "#                         strides=conv2_stride, padding=conv2_pad,\n",
    "#                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "with tf.name_scope(\"pool1\"):\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=\"VALID\") \n",
    "    \n",
    "#    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 75 * 75])\n",
    "    \n",
    "with tf.name_scope(\"conv2\"):\n",
    "    conv2 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "    \n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=\"VALID\")\n",
    "    \n",
    "with tf.name_scope(\"conv3\"):\n",
    "    conv3 = tf.layers.conv2d(conv2, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                         strides=conv3_stride, padding=conv3_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv3\")\n",
    "    \n",
    "with tf.name_scope(\"conv4\"):\n",
    "    conv4 = tf.layers.conv2d(conv3, filters=conv4_fmaps, kernel_size=conv4_ksize,\n",
    "                         strides=conv4_stride, padding=conv4_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv4\")\n",
    "    \n",
    "with tf.name_scope(\"conv5\"):\n",
    "    conv5 = tf.layers.conv2d(conv4, filters=conv5_fmaps, kernel_size=conv5_ksize,\n",
    "                         strides=conv5_stride, padding=conv5_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv5\")\n",
    "    \n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=\"VALID\")\n",
    "    print(\"pool3\",pool3)\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 19 * 19])\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    \n",
    "with tf.name_scope(\"fc2\"):\n",
    "    fc2 = tf.layers.dense(fc1, n_fc2, activation=tf.nn.relu, name=\"fc2\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc2, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                              labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "X_raw = np.r_[X_fake_f, X_real_f]                                               # concat fake and real smile samples together\n",
    "y_raw = np.r_[y_fake, y_real]                                                   # 1: fake, 0: real\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, \n",
    "                                                    test_size=0.3)              # split randomly into train and test datasets\n",
    "\n",
    "n_epochs = 50                                                                    # number of epochs to train this model. The larger the better\n",
    "num_of_batches = 5                                                              # split the training data into batches to avoid insufficient memory error\n",
    "batch_size = int(X_train.shape[0] / num_of_batches)                             # number of samples in each batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        acc_train = 0\n",
    "        acc_test = 0\n",
    "        \n",
    "        for batch in range(num_of_batches):                                     # feed in the training data one batch at a time\n",
    "            from_i = batch*batch_size\n",
    "            to_i = (batch+1)*batch_size\n",
    "            \n",
    "            if batch != num_of_batches-1:                                       # not last batch?\n",
    "                sess.run(training_op, feed_dict={X: X_train[from_i:to_i], \n",
    "                                                 y: y_train[from_i:to_i]})\n",
    "            else:                                                               # last batch\n",
    "                sess.run(training_op, feed_dict={X: X_train[from_i:], \n",
    "                                                 y: y_train[from_i:]})\n",
    "                \n",
    "            acc_train += accuracy.eval(feed_dict={X: X_train[from_i:to_i], \n",
    "                                     y: y_train[from_i:to_i]}) / num_of_batches\n",
    "            acc_test  += accuracy.eval(feed_dict={X: X_test, \n",
    "                                                  y: y_test}) / num_of_batches\n",
    "            \n",
    "        pred_fake_test = sess.run(Y_proba, feed_dict={X: X_test, y: y_test})    # get the output (Y_proba) of the model\n",
    "        pred_fake_indices_test = np.where(pred_fake_test[:,1]>=0.5)             # get the indices of the samples that is predicted \"fake\". If Y_proba >= 0.5, then it is predicted \"fake\"\n",
    "        pred_real_indices_test = np.where(pred_fake_test[:,1]<0.5)              # get the indices of the samples that is predicted \"real\".if Y_proba < 0.5, then it is predicted \"real\"\n",
    "        \n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "         \n",
    "    print(\"Saving the results...\")\n",
    "    shutil.rmtree(folder_results_fake_test, ignore_errors=True)                 # remove the folder if it already exists\n",
    "    os.makedirs(folder_results_fake_test)                                       # create a new folder\n",
    "    shutil.rmtree(folder_results_real_test, ignore_errors=True)                 # remove the folder if it already exists\n",
    "    os.makedirs(folder_results_real_test)                                       # create a new folder\n",
    "    \n",
    "    for i,j in np.ndenumerate(pred_fake_indices_test):                          # save all the predicted \"fake\" samples into the folder\n",
    "        plt.imsave(folder_results_fake_test+\"/fake_smile_pred_test_\"+str(i[1])\n",
    "                                            +\".jpg\",X_test[j,:,:], cmap='gray')\n",
    "    for i,j in np.ndenumerate(pred_real_indices_test):                          # save all the predicted \"real\" samples into the folder\n",
    "        plt.imsave(folder_results_real_test+\"/real_smile_pred_test_\"+str(i[1])\n",
    "                                            +\".jpg\",X_test[j,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ed6cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
