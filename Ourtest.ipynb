{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8271f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Loading pre-cropped faces from folder...\n",
      "Training CNN...\n",
      "conv21 Tensor(\"conv21/conv21/Relu:0\", shape=(?, 74, 74, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:234: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:563: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:244: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv21 = tf.layers.conv2d(pool1, filters=conv21_fmaps, kernel_size=conv21_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:251: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv22 = tf.layers.conv2d(conv21, filters=conv22_fmaps, kernel_size=conv22_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:256: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv31 = tf.layers.conv2d(conv22, filters=conv31_fmaps, kernel_size=conv31_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:261: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv32 = tf.layers.conv2d(conv31, filters=conv32_fmaps, kernel_size=conv32_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:266: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv41 = tf.layers.conv2d(conv32, filters=conv41_fmaps, kernel_size=conv41_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:271: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv42 = tf.layers.conv2d(conv41, filters=conv42_fmaps, kernel_size=conv42_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:276: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv51 = tf.layers.conv2d(conv42, filters=conv51_fmaps, kernel_size=conv51_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:281: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv52 = tf.layers.conv2d(conv51, filters=conv52_fmaps, kernel_size=conv52_ksize,\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:297: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  fc1 = tf.layers.dense(pool2_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv52 Tensor(\"conv52/conv52/Relu:0\", shape=(?, 2, 2, 512), dtype=float32)\n",
      "pool2 Tensor(\"pool2/MaxPool:0\", shape=(?, 1, 1, 512), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_17012/1935275520.py:300: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "1 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "2 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "3 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "4 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "5 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "6 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "7 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "8 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "9 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "10 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "11 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "12 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "13 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "14 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "15 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "16 Train accuracy: 0.9916666626930237 Test accuracy: 0.9811320900917053\n",
      "17 Train accuracy: 0.9666666507720947 Test accuracy: 0.9245283126831054\n",
      "18 Train accuracy: 0.9749999880790711 Test accuracy: 0.9735849261283874\n",
      "19 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "20 Train accuracy: 0.9749999880790711 Test accuracy: 0.9811320900917053\n",
      "21 Train accuracy: 0.9666666507720947 Test accuracy: 0.9735849261283875\n",
      "22 Train accuracy: 0.9666666507720947 Test accuracy: 0.9698113322257995\n",
      "23 Train accuracy: 0.9666666507720947 Test accuracy: 0.9811320900917053\n",
      "24 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "25 Train accuracy: 0.9833333253860475 Test accuracy: 0.9773585081100464\n",
      "26 Train accuracy: 0.9833333253860475 Test accuracy: 0.9698113441467286\n",
      "27 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "28 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "29 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "30 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "31 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "32 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "33 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "34 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "35 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "36 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "37 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "38 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "39 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "40 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "41 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "42 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "43 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "44 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "45 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "46 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "47 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "48 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "49 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "50 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "51 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "52 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "53 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "54 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "55 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "56 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "57 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "58 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "59 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "60 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "61 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "62 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "63 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "64 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "65 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "66 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "67 Train accuracy: 0.9916666626930237 Test accuracy: 0.9622641801834106\n",
      "68 Train accuracy: 0.9916666626930237 Test accuracy: 0.9622641801834106\n",
      "69 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "70 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "71 Train accuracy: 0.9916666626930237 Test accuracy: 0.9622641801834106\n",
      "72 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "73 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "74 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "75 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "76 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "77 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "78 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "79 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "80 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "81 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "82 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "83 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "84 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "85 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "86 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "87 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "88 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "89 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "90 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "91 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "92 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "93 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "94 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "95 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "96 Train accuracy: 0.9833333253860475 Test accuracy: 0.9622641801834106\n",
      "97 Train accuracy: 0.9916666626930237 Test accuracy: 0.9622641801834106\n",
      "98 Train accuracy: 0.9916666626930237 Test accuracy: 0.9622641801834106\n",
      "99 Train accuracy: 0.9916666626930237 Test accuracy: 0.9622641801834106\n",
      "Saving the results...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "folder_fake = 'C:/Users/DELL/Desktop/Newfolder/fake_smiles'\n",
    "folder_real = 'C:/Users/DELL/Desktop/Newfolder/true_smiles'\n",
    "\n",
    "folder_fake_faces = 'C:/Users/DELL/Desktop/Newfolder/fake_faces'\n",
    "folder_real_faces = 'C:/Users/DELL/Desktop/Newfolder/result/true_test_fromfaces'\n",
    "\n",
    "folder_results_fake_test  = 'C:/Users/DELL/Desktop/Newfolder/ourtest/fake_rt'\n",
    "folder_results_real_test  = 'C:/Users/DELL/Desktop/Newfolder/ourtest/true_rt'\n",
    "\n",
    "detect_face = 0                                                                 # 0: using the existing cropped face images. 1: use face detectFace to crop the faces out of the original image\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    '''\n",
    "    Input:\n",
    "        folder             :The path of the image folder.\n",
    "    Output:\n",
    "        images             :A (N,) numpy array, where N is the total number of \n",
    "                            images.\n",
    "    '''\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder,filename)).convert('L')            # open the image and convert to uint8 (gray scale)\n",
    "        img = np.array(img)                                                     # convert image to a numpy array\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "def resize_image(images, size):\n",
    "    '''\n",
    "    Input: \n",
    "        images             :An object of shape (N,). N is the total number of \n",
    "                            images.\n",
    "        size               :A ndarray (rows, cols) of the output image shape.\n",
    "    Output:\n",
    "        resized_images     :An (N,rows,cols) numpy array.\n",
    "    '''\n",
    "    resized_images = []\n",
    "    for i,j in enumerate(images):\n",
    "        resized_images.append(resize(images[i], ((size[0]),size[1]),            # resize the image\n",
    "                                     mode='reflect'))\n",
    "    resized_images = np.array(resized_images)                                   # convert image to a numpy array\n",
    "    return resized_images\n",
    "\n",
    "def detectFace(img):\n",
    "    '''\n",
    "    Input:\n",
    "        img                 : A gray scale image represented by numpy array.\n",
    "    Output:\n",
    "        bbox                : The four corners of bounding boxes for all \n",
    "                              detected faces in numpy arrray of shape (number \n",
    "                              of detected faces,4,2).\n",
    "                                ++++++++++++++++++\n",
    "                                +(x0,y0)  (x1,y1)+\n",
    "                                +                +\n",
    "                                +                +\n",
    "                                +      bbox      +\n",
    "                                +                +\n",
    "                                +                +\n",
    "                                +(x2,y2)  (x3,y3)+\n",
    "                                ++++++++++++++++++\n",
    "    '''\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    delta_scal = 0\n",
    "    while True:\n",
    "        faces = face_cascade.detectMultiScale(img, 3.0-delta_scal, 2)\n",
    "        if len(faces) != 0:                                                     # at least one face is detected\n",
    "            break\n",
    "        else:                                                                   # no face detected, re-detecting with new parameters...\n",
    "            if 3.0-delta_scal > 1.01:\n",
    "                delta_scal += 0.01\n",
    "            else:\n",
    "                break\n",
    "              \n",
    "    bbox = np.zeros([len(faces),4,2])\n",
    "        \n",
    "    for i, (x,y,w,h) in enumerate(faces):\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)                          # draw a red rectangle around the face  \n",
    "        bbox[i,:,:] = np.array([[y,x],[y,x+w],[y+h,x],[y+h,x+w]])\n",
    "        \n",
    "    if bbox.shape[0] != 1:\n",
    "        print(\"\\nWarning! Multiple faces detected! Image shown below...\")\n",
    "        plt.figure()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    return bbox[0,:,:].astype(int)\n",
    "\n",
    "new_size = [300,300]                                                            # the output size of all the images regardless of it's original shape\n",
    "\n",
    "if detect_face:\n",
    "    print(\"Loading original images..\")\n",
    "    images = load_images_from_folder(folder_fake)                               # load images from folder\n",
    "    X_fake = resize_image(images,new_size)                                      # resize to 300*300\n",
    "    \n",
    "    images = load_images_from_folder(folder_real)\n",
    "    X_real = resize_image(images,new_size)\n",
    "    \n",
    "    X_fake_f = np.zeros([X_fake.shape[0],new_size[0],new_size[1]])\n",
    "    X_real_f = np.zeros([X_real.shape[0],new_size[0],new_size[1]])\n",
    "    \n",
    "    toolbar_width = 1                                                           # not important, just for printing purpose...\n",
    "    sys.stdout.write(\"%s\\r\" % (\" \" * toolbar_width))                            # not important, just for printing purpose...\n",
    "    sys.stdout.flush()                                                          # not important, just for printing purpose...\n",
    "    sys.stdout.write(\"\\b\" * (toolbar_width+1))                                  # not important, just for printing purpose...\n",
    "    \n",
    "    shutil.rmtree(folder_fake_faces, ignore_errors=True)                        # remove the folder if it already exists\n",
    "    os.makedirs(folder_fake_faces)                                              # create a new folder\n",
    "    shutil.rmtree(folder_real_faces, ignore_errors=True)                        # remove the folder if it already exists\n",
    "    os.makedirs(folder_real_faces)                                              # create a new folder\n",
    "    \n",
    "    for i in range(X_fake.shape[0]):\n",
    "        bbox = detectFace((255*X_fake[i,:,:]).astype('uint8'))                  # detects the face of the original image\n",
    "        face_i = X_fake[i,bbox[0,0]:bbox[2,0],bbox[0,1]:bbox[1,1]]              # crop out the face from the original image\n",
    "        X_fake_f[i,:,:] = resize(face_i, (new_size[0],new_size[1]),\n",
    "                                 mode='reflect')                                # resize to 300*300\n",
    "        plt.imsave(folder_fake_faces+\"/fake_smile_\"+str(i)+\".jpg\",\n",
    "                   X_fake_f[i,:,:], cmap='gray')                                # save the detected face\n",
    "        \n",
    "        sys.stdout.write(\"\\rDetecting and saving fake smile faces...%.1f%%\" % \n",
    "                         (i*100/(X_fake.shape[0]-1)))                           # not important, just for printing purpose...\n",
    "        sys.stdout.flush()                                                      # not important, just for printing purpose...\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "        \n",
    "    for i in range(X_real.shape[0]):\n",
    "        bbox = detectFace((255*X_real[i,:,:]).astype('uint8'))                  # detects the face of the original image\n",
    "        face_i = X_real[i,bbox[0,0]:bbox[2,0],bbox[0,1]:bbox[1,1]]              # crop out the face from the original image\n",
    "        X_real_f[i,:,:] = resize(face_i, (new_size[0],new_size[1]), \n",
    "                                 mode='reflect')                                # resize to 300*300\n",
    "        plt.imsave(folder_real_faces+\"/real_smile\"+str(i)+\".jpg\",\n",
    "                   X_real_f[i,:,:], cmap='gray')                                # save the detected face\n",
    "        \n",
    "        sys.stdout.write(\"\\rDetecting and saving real smile faces...%.1f%%\" % \n",
    "                         (i*100/(X_real.shape[0]-1)))                           # not important, just for printing purpose...\n",
    "        sys.stdout.flush()                                                      # not important, just for printing purpose...\n",
    "    \n",
    "    sys.stdout.write(\"\\n\")                                                      # not important, just for printing purpose...\n",
    "else:\n",
    "    print(\"Loading pre-cropped faces from folder...\")\n",
    "    images = load_images_from_folder(folder_fake_faces)                         # load images from folder\n",
    "    X_fake_f = resize_image(images,new_size)                                    # resize to 300*300\n",
    "    \n",
    "    images = load_images_from_folder(folder_real_faces)                         # load images from folder\n",
    "    X_real_f = resize_image(images,new_size)                                    # resize to 300*300\n",
    "    \n",
    "y_fake = np.ones([X_fake_f.shape[0]])                                           # fake smile labels: 1\n",
    "y_real = np.zeros([X_real_f.shape[0]])                                          # real smile labels: 0\n",
    "\n",
    "print(\"Training CNN...\")\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    #tf.reset_default_graph()\n",
    "#    tf.set_random_seed(seed)\n",
    "     np.random.seed(seed)                                                       # uncomment if want to make train test split return the same samples every time\n",
    "\n",
    "height = new_size[0]\n",
    "width = new_size[1]\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 64\n",
    "conv1_ksize = 7\n",
    "conv1_stride = 2\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv21_fmaps = 64\n",
    "conv21_ksize = 3\n",
    "conv21_stride = 1\n",
    "conv21_pad = \"SAME\"\n",
    "\n",
    "conv22_fmaps = 64\n",
    "conv22_ksize = 3\n",
    "conv22_stride = 1\n",
    "conv22_pad = \"SAME\"\n",
    "\n",
    "conv31_fmaps = 128\n",
    "conv31_ksize = 3\n",
    "conv31_stride = 2\n",
    "conv31_pad = \"SAME\"\n",
    "\n",
    "conv32_fmaps = 128\n",
    "conv32_ksize = 3\n",
    "conv32_stride = 2\n",
    "conv32_pad = \"SAME\"\n",
    "\n",
    "conv41_fmaps = 256\n",
    "conv41_ksize = 3\n",
    "conv41_stride = 2\n",
    "conv41_pad = \"SAME\"\n",
    "\n",
    "conv42_fmaps = 256\n",
    "conv42_ksize = 3\n",
    "conv42_stride = 2\n",
    "conv42_pad = \"SAME\"\n",
    "\n",
    "conv51_fmaps = 512\n",
    "conv51_ksize = 3\n",
    "conv51_stride = 2\n",
    "conv51_pad = \"SAME\"\n",
    "\n",
    "conv52_fmaps = 512\n",
    "conv52_ksize = 3\n",
    "conv52_stride = 2\n",
    "conv52_pad = \"SAME\"\n",
    "\n",
    "pool2_fmaps = conv52_fmaps\n",
    "\n",
    "n_fc1 = 1000\n",
    "n_outputs = 2\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, \n",
    "                         kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "with tf.name_scope(\"pool1\"):\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=\"VALID\")\n",
    "    \n",
    "with tf.name_scope(\"conv21\"):\n",
    "    conv21 = tf.layers.conv2d(pool1, filters=conv21_fmaps, kernel_size=conv21_ksize,\n",
    "                         strides=conv21_stride, padding=conv21_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv21\")\n",
    "    print(\"conv21\", conv21)\n",
    "    tf.get_variable('conv21/conv21', shape=[1, 74, 74, 64])\n",
    "    \n",
    "with tf.name_scope(\"conv22\"):\n",
    "    conv22 = tf.layers.conv2d(conv21, filters=conv22_fmaps, kernel_size=conv22_ksize,\n",
    "                         strides=conv22_stride, padding=conv22_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv22\")\n",
    "    \n",
    "with tf.name_scope(\"conv31\"):\n",
    "    conv31 = tf.layers.conv2d(conv22, filters=conv31_fmaps, kernel_size=conv31_ksize,\n",
    "                         strides=conv31_stride, padding=conv31_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv31\")\n",
    "    \n",
    "with tf.name_scope(\"conv32\"):\n",
    "    conv32 = tf.layers.conv2d(conv31, filters=conv32_fmaps, kernel_size=conv32_ksize,\n",
    "                         strides=conv32_stride, padding=conv32_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv32\")\n",
    "    \n",
    "with tf.name_scope(\"conv41\"):\n",
    "    conv41 = tf.layers.conv2d(conv32, filters=conv41_fmaps, kernel_size=conv41_ksize,\n",
    "                         strides=conv41_stride, padding=conv41_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv41\")\n",
    "    \n",
    "with tf.name_scope(\"conv42\"):\n",
    "    conv42 = tf.layers.conv2d(conv41, filters=conv42_fmaps, kernel_size=conv42_ksize,\n",
    "                         strides=conv42_stride, padding=conv42_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv42\")\n",
    "    \n",
    "with tf.name_scope(\"conv51\"):\n",
    "    conv51 = tf.layers.conv2d(conv42, filters=conv51_fmaps, kernel_size=conv51_ksize,\n",
    "                         strides=conv51_stride, padding=conv51_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv51\")\n",
    "    \n",
    "with tf.name_scope(\"conv52\"):\n",
    "    conv52 = tf.layers.conv2d(conv51, filters=conv52_fmaps, kernel_size=conv52_ksize,\n",
    "                         strides=conv52_stride, padding=conv52_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv52\")\n",
    "    print(\"conv52\", conv52)\n",
    "    tf.get_variable('conv52/conv52', shape=[1, 2, 2, 512])\n",
    "    \n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv52, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=\"VALID\")\n",
    "#    pool2 = tf.nn.avg_pool(conv52, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "#                           padding=\"VALID\")\n",
    "    \n",
    "    print(\"pool2\",pool2)\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, pool2_fmaps * 1 * 1])\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool2_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                              labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "X_raw = np.r_[X_fake_f, X_real_f]                                               # concat fake and real smile samples together\n",
    "y_raw = np.r_[y_fake, y_real]                                                   # 1: fake, 0: real\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X_raw, y_raw,test_size=0.3)              # split randomly into train and test datasets\n",
    "\n",
    "n_epochs = 100                                                                    # number of epochs to train this model. The larger the better\n",
    "num_of_batches = 5                                                              # split the training data into batches to avoid insufficient memory error\n",
    "batch_size = int(X_train.shape[0] / num_of_batches)                             # number of samples in each batch\n",
    "\n",
    "#filter_summary = tf.summary.image('conv21',conv21)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#    summary_writer = tf.summary.FileWriter('/tmp/logs', sess.graph_def)\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        acc_train = 0\n",
    "        acc_test = 0\n",
    "        \n",
    "        for batch in range(num_of_batches):                                     # feed in the training data one batch at a time\n",
    "            from_i = batch*batch_size\n",
    "            to_i = (batch+1)*batch_size\n",
    "            \n",
    "            if batch != num_of_batches-1:                                       # not last batch?\n",
    "                sess.run(training_op, feed_dict={X: X_train[from_i:to_i], \n",
    "                                                 y: y_train[from_i:to_i]})\n",
    "            else:                                                               # last batch\n",
    "                sess.run(training_op, feed_dict={X: X_train[from_i:], \n",
    "                                                 y: y_train[from_i:]})\n",
    "                \n",
    "            acc_train += accuracy.eval(feed_dict={X: X_train[from_i:to_i], \n",
    "                                     y: y_train[from_i:to_i]}) / num_of_batches\n",
    "            acc_test  += accuracy.eval(feed_dict={X: X_test, \n",
    "                                                  y: y_test}) / num_of_batches\n",
    "            \n",
    "        pred_fake_test = sess.run(Y_proba, feed_dict={X: X_test, y: y_test})    # get the output (Y_proba) of the model\n",
    "        pred_fake_indices_test = np.where(pred_fake_test[:,1]>=0.5)             # get the indices of the samples that is predicted \"fake\". If Y_proba >= 0.5, then it is predicted \"fake\"\n",
    "        pred_real_indices_test = np.where(pred_fake_test[:,1]<0.5)              # get the indices of the samples that is predicted \"real\".if Y_proba < 0.5, then it is predicted \"real\"\n",
    "        \n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "         \n",
    "    print(\"Saving the results...\")\n",
    "    \n",
    "#    summary_writer.add_summary(filter_summary)\n",
    "    \n",
    "    shutil.rmtree(folder_results_fake_test, ignore_errors=True)                 # remove the folder if it already exists\n",
    "    os.makedirs(folder_results_fake_test)                                       # create a new folder\n",
    "    shutil.rmtree(folder_results_real_test, ignore_errors=True)                 # remove the folder if it already exists\n",
    "    os.makedirs(folder_results_real_test)                                       # create a new folder\n",
    "    \n",
    "    for i,j in np.ndenumerate(pred_fake_indices_test):                          # save all the predicted \"fake\" samples into the folder\n",
    "        plt.imsave(folder_results_fake_test+\"/fake_smile_pred_test_\"+str(i[1])\n",
    "                                            +\".jpg\",X_test[j,:,:], cmap='gray')\n",
    "    for i,j in np.ndenumerate(pred_real_indices_test):                          # save all the predicted \"real\" samples into the folder\n",
    "        plt.imsave(folder_results_real_test+\"/real_smile_pred_test_\"+str(i[1])\n",
    "                                            +\".jpg\",X_test[j,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356af4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
